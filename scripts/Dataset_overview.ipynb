{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv \n",
    "import utils\n",
    "from DataSet import DataSet\n",
    "import pandas as pd\n",
    "import inflect\n",
    "#import seaborn as sns\n",
    "#sns.set_theme(style=\"whitegrid\")\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# print full dataframes:\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('experiment1', '3'), ('experiment2', '4'), ('experiment3', '5_pilot'), ('scalar_heat', '5_scalar_heat')]\n"
     ]
    }
   ],
   "source": [
    "lexical_data = utils.load_lexical_data()\n",
    "\n",
    "\n",
    "leopard = [('experiment1', '3'), ('experiment2', '4')]\n",
    "current = [('experiment3', '5_pilot'), ('scalar_heat','5_scalar_heat')]\n",
    "total = leopard  +current\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/clean/diagnostic_dataset/annotations_clean_contradictions_batch_0.5/run3-group_experiment1/*.csv\n",
      "experiment1 3 32994\n",
      "../data/clean/diagnostic_dataset/annotations_clean_contradictions_batch_0.5/run4-group_experiment2/*.csv\n",
      "experiment2 4 108022\n",
      "../data/clean/diagnostic_dataset/annotations_clean_contradictions_batch_0.5/run5_pilot-group_experiment3/*.csv\n",
      "experiment3 5_pilot 98714\n",
      "../data/clean/diagnostic_dataset/annotations_clean_contradictions_batch_0.5/run5_scalar_heat-group_scalar_heat/*.csv\n",
      "scalar_heat 5_scalar_heat 14145\n",
      "253875\n"
     ]
    }
   ],
   "source": [
    "# clean\n",
    "source = 'clean'\n",
    "\n",
    "all_data = []\n",
    "for group, run in total:\n",
    "    d = utils.load_data(run, group, source)\n",
    "    print(group, run, len(d))\n",
    "    all_data.extend(d)\n",
    "print(len(all_data))\n",
    "data_set_clean = DataSet(all_data, lexical_data, metric = 'prop_true')\n",
    "#data/clean/diagnostic_dataset/annotations_clean_contradictions_batch_0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_found_in_kitchens, does_live_in_water, is_white, is_eaten_edible, has_skin, is_pink, is_a_plant, has_leaves, has_a_stalk_stem, has_teeth, is_dangerous, is_clothing, is_a_vegetable, made_of_metal, has_an_engine, made_of_fabric_cloth_material, has_a_seat_seats, made_of_glass, is_green, has_a_tail, does_make_music, is_an_insect, made_of_wood, is_red, is_pretty_attractive_beautiful, is_soft, is_sharp, is_tasty, has_skin_peel, is_fast, is_long, is_a_mammal, is_food, is_a_vehicle, is_strong, is_juicy, has_claws, is_healthy, has_pips_seeds, is_sweet, has_flesh, is_circular_round, is_small, is_found_in_seas, is_an_animal, has_roots, made_of_cotton, is_a_fruit, is_tall, has_fur_hair, is_grown, does_grow, has_legs, is_for_children, is_a_tool, does_lay_eggs, is_useful, has_four_legs, does_smell_is_smelly, is_played_does_play, does_fly, is_hard, has_a_beak, is_a_bird, is_expensive, is_a_weapon, made_of_plastic, keeps_warm_makes_warm, has_wings, does_swim, does_kill, is_yellow, has_keys, has_eyes, has_a_blade_blades, is_brown, is_thin, is_a_musical_instrument, has_a_point, is_black, has_a_handle_handles, is_colourful, has_feathers, does_eat, does_carry_transport, has_wheels, is_noisy_loud, is_edible, is_heavy, is_worn, is_used_in_cooking, does_protect, is_big_large\n"
     ]
    }
   ],
   "source": [
    "# pilot data properties \n",
    "\n",
    "path = '../data/aggregated/pilot_blackbox/blackbox_dataset.csv'\n",
    "\n",
    "with open(path) as infile:\n",
    "    data = list(csv.DictReader(infile))\n",
    "    \n",
    "properties = set()\n",
    "\n",
    "for d in data:\n",
    "    properties.add(d['property'])\n",
    "\n",
    "print(', '.join(properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('red', 'fenugreek') few\n"
     ]
    }
   ],
   "source": [
    "for p, pair in data_set_clean.pairs.items():\n",
    "    print(p, pair.ml_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw_annonymised/diagnostic_dataset/run3-group_experiment1/*.csv\n",
      "experiment1 3 0\n",
      "../data/raw_annonymised/diagnostic_dataset/run4-group_experiment2/*.csv\n",
      "experiment2 4 0\n",
      "../data/raw_annonymised/diagnostic_dataset/run5_pilot-group_experiment3/*.csv\n",
      "experiment3 5_pilot 0\n",
      "../data/raw_annonymised/diagnostic_dataset/run5_scalar_heat-group_scalar_heat/*.csv\n",
      "scalar_heat 5_scalar_heat 0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "source = 'raw'\n",
    "\n",
    "all_data = []\n",
    "for group, run in total:\n",
    "    d = utils.load_data(run, group, source)\n",
    "    print(group, run, len(d))\n",
    "    all_data.extend(d)\n",
    "print(len(all_data))\n",
    "data_set_full = DataSet(all_data, lexical_data, metric = 'prop_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'few', 'all-some', None, 'few-some', 'some', 'all'}\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  total n \\\\\n",
      "\\midrule\n",
      "coarse-grained relations &  5 \\\\\n",
      "concepts                 &  1756 \\\\\n",
      "fine-grained relations   &  12 \\\\\n",
      "pairs                    &  3304 \\\\\n",
      "properties               &  21 \\\\\n",
      "units                    &  30650 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_general_overview(dataset_clean):\n",
    "    \n",
    "    data_dict = dict()\n",
    "    data_dict['total n'] =  {\n",
    "    'units': len(dataset_clean.units),\n",
    "    'pairs': len(dataset_clean.pairs),\n",
    "    'concepts': len(dataset_clean.concept_sets),\n",
    "    'properties': len(dataset_clean.prop_sets),\n",
    "    'fine-grained relations': len(dataset_clean.relation_sets),\n",
    "    'coarse-grained relations': len(set([pair.ml_label for p, pair in \n",
    "                                         dataset_clean.pairs.items() if pair.ml_label is not None]))\n",
    "    }\n",
    "    print(set([pair.ml_label for p, pair in dataset_clean.pairs.items()]))\n",
    "    return data_dict\n",
    "    \n",
    "overview_dict = get_general_overview(data_set_clean)\n",
    "df = pd.DataFrame(overview_dict)\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &    raw &  clean \\\\\n",
      "\\midrule\n",
      "mean annotations per unit &  10.08 &  8.06 \\\\\n",
      "Krip. alpha               &  0.36 &  0.40 \\\\\n",
      "mean duration per unit    &  9.24 &  9.25 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def overview_processing(data_set):\n",
    "    data_dict = {\n",
    "   \n",
    "        #'annotations': len(data_set.annotations),\n",
    "        'mean annotations per unit': sum([len(u.annotations) \n",
    "                                          for u in data_set.units])/len(data_set.units),\n",
    "        'Krip. alpha ': data_set.get_alpha(),\n",
    "\n",
    "        'mean duration per unit': data_set.get_clean_average_seconds(),\n",
    "    }\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "data_dict_full = dict()\n",
    "data_dict_full['raw'] = overview_processing(data_set_full)\n",
    "data_dict_full['clean'] = overview_processing(data_set_clean)\n",
    "\n",
    "df  = pd.DataFrame(data_dict_full).round(2)\n",
    "print(df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &   mean \\\\\n",
      "\\midrule\n",
      "examples neg      &  57.43 \\\\\n",
      "examples no label &  13.81 \\\\\n",
      "examples pos      &  86.10 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def overview_props(dataset):\n",
    "    \n",
    "    data_dict = dict()\n",
    "    data_dict['mean'] = dict()\n",
    "    \n",
    "#     pos_labels = ['all', 'all-some', 'some', 'few-some']\n",
    "#     neg_labels = ['few']\n",
    "    \n",
    "    total_pos = []\n",
    "    total_neg = []\n",
    "    total_no = []\n",
    "    \n",
    "    for prop, prop_set in dataset.prop_sets.items():\n",
    "        labels = []\n",
    "        total_pos.append(len(prop_set.pos.pairs))\n",
    "        total_neg.append(len(prop_set.neg.pairs))\n",
    "        total_no.append(len(prop_set.nolabel.pairs))\n",
    "    data_dict['mean']['examples pos'] = sum(total_pos)/len(total_pos)\n",
    "    data_dict['mean']['examples neg'] = sum(total_neg)/len(total_neg)\n",
    "    data_dict['mean']['examples no label'] = sum(total_no)/len(total_no)\n",
    "    return data_dict\n",
    "    \n",
    "\n",
    "data_dict = overview_props(data_set_clean)  \n",
    "df = pd.DataFrame(data_dict)\n",
    "print(df.round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "            relation &  alpha &  seconds &  pairs &  properties &  candidate pairs \\\\\n",
      "\\midrule\n",
      " creative &  0.17 &  7.55 &  400 &  21 &  3095 \\\\\n",
      " rare &  0.28 &  7.07 &  630 &  21 &  3095 \\\\\n",
      " impossible &  0.41 &  8.04 &  617 &  21 &  3095 \\\\\n",
      " implied\\_category &  0.53 &  7.73 &  1060 &  21 &  3045 \\\\\n",
      " typical\\_of\\_property &  0.42 &  7.23 &  633 &  21 &  3045 \\\\\n",
      " unusual &  0.30 &  8.11 &  839 &  21 &  3095 \\\\\n",
      " variability\\_open &  0.32 &  9.05 &  672 &  17 &  2422 \\\\\n",
      " typical\\_of\\_concept &  0.55 &  6.84 &  1056 &  21 &  3045 \\\\\n",
      " affording\\_activity &  0.51 &  7.22 &  732 &  17 &  2422 \\\\\n",
      " variability\\_limited &  0.34 &  9.32 &  967 &  21 &  3045 \\\\\n",
      " afforded\\_unusual &  0.27 &  9.40 &  107 &  4 &  623 \\\\\n",
      " afforded\\_usual &  0.63 &  7.81 &  214 &  4 &  623 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# relation overview\n",
    "\n",
    "rel_type = 'fine-grained'\n",
    "rel_dict = data_set_clean.get_relation_overview(rel_type)\n",
    "df = pd.DataFrame(rel_dict).round(2)\n",
    "print(df.to_latex(index=False))\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      " relation &  alpha &  seconds &  pairs &  properties &  candidate pairs \\\\\n",
      "\\midrule\n",
      " few &  0.36 &  7.66 &  2289 &  21 &  10908 \\\\\n",
      " all &  0.53 &  7.87 &  3092 &  21 &  7996 \\\\\n",
      " None &  0.07 &  7.64 &  50 &  21 &  2410 \\\\\n",
      " all-some &  0.49 &  8.28 &  827 &  19 &  1936 \\\\\n",
      " some &  0.29 &  9.32 &  1475 &  20 &  6690 \\\\\n",
      " few-some &  0.29 &  6.99 &  194 &  17 &  710 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coarse-grained\n",
    "\n",
    "rel_type = 'coarse-grained'\n",
    "rel_dict = data_set_clean.get_relation_overview(rel_type)\n",
    "df = pd.DataFrame(rel_dict).round(2)\n",
    "print(df.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_concept_overview(data_set):\n",
    "    concept_dict = defaultdict(list)\n",
    "    for p, pair in data_set.pairs.items():\n",
    "        prop, concept = p\n",
    "        concept_dict[c].append(pair)\n",
    "        \n",
    "    total_pairs = []\n",
    "    total_pos = []\n",
    "    total_neg = []\n",
    "    total_no = []\n",
    "    \n",
    "    for c, pairs in concept_dict.items():\n",
    "        labels = []\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  mean \\\\\n",
      "\\midrule\n",
      "properties        &  1.88 \\\\\n",
      "positive examples &  1.03 \\\\\n",
      "negative examples &  0.69 \\\\\n",
      "invalid examples  &  0.17 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_concept_distribution(data_set):\n",
    "    concept_label_dict = defaultdict(list)\n",
    "    pos_labels = ['all', 'all-some', 'some', 'few-some']\n",
    "    neg_labels = ['few']\n",
    "    for c, concept in data_set.concept_sets.items():\n",
    "        for p, pair in concept.pairs.items():\n",
    "            concept_label_dict[c].append('properties')\n",
    "            ml_label = pair.ml_label\n",
    "            if ml_label in pos_labels:\n",
    "                concept_label_dict[c].append('positive examples')\n",
    "            elif ml_label in neg_labels:\n",
    "                concept_label_dict[c].append('negative examples')\n",
    "            else:\n",
    "                concept_label_dict[c].append('invalid examples')\n",
    "\n",
    "    cols = ['properties', 'positive examples', 'negative examples', 'invalid examples']\n",
    "\n",
    "    data_dict = dict()\n",
    "\n",
    "    for col in cols:\n",
    "        d = dict()\n",
    "        counts = []\n",
    "        for c, labels in concept_label_dict.items():\n",
    "            cnt = labels.count(col)\n",
    "            counts.append(cnt)\n",
    "        mean = sum(counts)/len(counts)\n",
    "        d['mean'] = mean\n",
    "        data_dict[col] = d\n",
    "        \n",
    "    return data_dict\n",
    "\n",
    "data_dict = get_concept_distribution(data_set_clean)\n",
    "df = pd.DataFrame(data_dict)\n",
    "print(df.round(2).T.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation configurations\n",
    "\n",
    "def get_configs(data_set, single=True):\n",
    "    \n",
    "    config_pair_dict = defaultdict(list)\n",
    "    config_prop_dict = defaultdict(set)\n",
    "    \n",
    "    \n",
    "    for p, pair in data_set.pairs.items():\n",
    "        prop, concept = p\n",
    "        rels = pair.relations\n",
    "        config = ' '.join((sorted(rels)))\n",
    "        if single==True:\n",
    "            if len(rels) == 1:\n",
    "                config_pair_dict[config].append(p)\n",
    "                config_prop_dict[config].add(prop)\n",
    "        else:\n",
    "            config_pair_dict[config].append(p)\n",
    "            config_prop_dict[config].add(prop)\n",
    "            \n",
    "        \n",
    "    config_dict = dict()\n",
    "    for conf, pairs in config_pair_dict.items():\n",
    "        d = dict()\n",
    "        d['pairs'] = len(pairs)\n",
    "        d['properties'] = len(config_prop_dict[conf])\n",
    "        config_dict[conf] = d\n",
    "    return config_dict\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrr}\n",
      "\\toprule\n",
      "{} &  pairs &  properties \\\\\n",
      "\\midrule\n",
      "impossible                                                                                     &  313 &  19 \\\\\n",
      "                                                                                               &  274 &  21 \\\\\n",
      "rare unusual                                                                                   &  242 &  19 \\\\\n",
      "affording\\_activity implied\\_category typical\\_of\\_concept typical\\_of\\_property variability\\_limited &  179 &  12 \\\\\n",
      "variability\\_open                                                                               &  175 &  12 \\\\\n",
      "creative impossible                                                                            &  170 &  18 \\\\\n",
      "affording\\_activity implied\\_category typical\\_of\\_concept typical\\_of\\_property                     &  155 &  13 \\\\\n",
      "variability\\_limited                                                                            &  114 &  15 \\\\\n",
      "affording\\_activity implied\\_category typical\\_of\\_concept variability\\_limited                     &  100 &  11 \\\\\n",
      "rare unusual variability\\_limited                                                               &  93 &  13 \\\\\n",
      "afforded\\_usual implied\\_category typical\\_of\\_concept typical\\_of\\_property                         &  88 &  4 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_dict = get_configs(data_set_clean, single=False)\n",
    "df = pd.DataFrame(config_dict)\n",
    "print(df.T.sort_values('pairs', ascending = False)[:11].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairs</th>\n",
       "      <th>properties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>impossible</th>\n",
       "      <td>313</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variability_open</th>\n",
       "      <td>175</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variability_limited</th>\n",
       "      <td>114</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unusual</th>\n",
       "      <td>84</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creative</th>\n",
       "      <td>23</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afforded_unusual</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rare</th>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implied_category</th>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>affording_activity</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typical_of_concept</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afforded_usual</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pairs  properties\n",
       "impossible           313    19        \n",
       "variability_open     175    12        \n",
       "variability_limited  114    15        \n",
       "unusual              84     20        \n",
       "creative             23     14        \n",
       "afforded_unusual     20     2         \n",
       "rare                 19     10        \n",
       "implied_category     16     8         \n",
       "affording_activity   4      3         \n",
       "typical_of_concept   4      4         \n",
       "afforded_usual       3      2         "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict = get_configs(data_set_clean, single=True)\n",
    "df = pd.DataFrame(config_dict)\n",
    "df.T.sort_values('pairs', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
